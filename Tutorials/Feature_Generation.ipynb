{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature_Generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4AkTMo16F7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing, metrics\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Set up code checking\n",
        "from learntools.core import binder\n",
        "binder.bind(globals())\n",
        "from learntools.feature_engineering.ex3 import *\n",
        "\n",
        "# Create features from   timestamps\n",
        "click_data = pd.read_csv('../input/feature-engineering-data/train_sample.csv', \n",
        "                         parse_dates=['click_time'])\n",
        "click_times = click_data['click_time']\n",
        "clicks = click_data.assign(day=click_times.dt.day.astype('uint8'),\n",
        "                           hour=click_times.dt.hour.astype('uint8'),\n",
        "                           minute=click_times.dt.minute.astype('uint8'),\n",
        "                           second=click_times.dt.second.astype('uint8'))\n",
        "\n",
        "# Label encoding for categorical features\n",
        "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
        "for feature in cat_features:\n",
        "    label_encoder = preprocessing.LabelEncoder()\n",
        "    clicks[feature] = label_encoder.fit_transform(clicks[feature])\n",
        "    \n",
        "def get_data_splits(dataframe, valid_fraction=0.1):\n",
        "\n",
        "    dataframe = dataframe.sort_values('click_time')\n",
        "    valid_rows = int(len(dataframe) * valid_fraction)\n",
        "    train = dataframe[:-valid_rows * 2]\n",
        "    # valid size == test size, last two sections of the data\n",
        "    valid = dataframe[-valid_rows * 2:-valid_rows]\n",
        "    test = dataframe[-valid_rows:]\n",
        "    \n",
        "    return train, valid, test\n",
        "\n",
        "def train_model(train, valid, test=None, feature_cols=None):\n",
        "    if feature_cols is None:\n",
        "        feature_cols = train.columns.drop(['click_time', 'attributed_time',\n",
        "                                           'is_attributed'])\n",
        "    dtrain = lgb.Dataset(train[feature_cols], label=train['is_attributed'])\n",
        "    dvalid = lgb.Dataset(valid[feature_cols], label=valid['is_attributed'])\n",
        "    \n",
        "    param = {'num_leaves': 64, 'objective': 'binary', \n",
        "             'metric': 'auc', 'seed': 7}\n",
        "    num_round = 1000\n",
        "    print(\"Training model. Hold on a minute to see the validation score\")\n",
        "    bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], \n",
        "                    early_stopping_rounds=20, verbose_eval=False)\n",
        "    \n",
        "    valid_pred = bst.predict(valid[feature_cols])\n",
        "    valid_score = metrics.roc_auc_score(valid['is_attributed'], valid_pred)\n",
        "    print(f\"Validation AUC score: {valid_score}\")\n",
        "    \n",
        "    if test is not None: \n",
        "        test_pred = bst.predict(test[feature_cols])\n",
        "        test_score = metrics.roc_auc_score(test['is_attributed'], test_pred)\n",
        "        return bst, valid_score, test_score\n",
        "    else:\n",
        "        return bst, valid_score\n",
        "\n",
        "print(\"Baseline model score\")\n",
        "train, valid, test = get_data_splits(clicks)\n",
        "_ = train_model(train, valid)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}