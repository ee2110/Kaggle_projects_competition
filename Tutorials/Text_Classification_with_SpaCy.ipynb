{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification_with_SpaCy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdNCCuUruTPR",
        "colab_type": "text"
      },
      "source": [
        "# **Text Classification**\n",
        "A common task in NLP is text classification. This is \"classification\" in the conventional machine learning sense, and it is applied to text. Examples include spam detection, sentiment analysis, and tagging customer queries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3HKLy42t77c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.util import minibatch\n",
        "import random\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NER59qvg8yH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(csv_file, split=0.9):\n",
        "    data = pd.read_csv(csv_file)\n",
        "    \n",
        "    # Shuffle data\n",
        "    train_data = data.sample(frac=1, random_state=7)\n",
        "    \n",
        "    texts = train_data.text.values\n",
        "    labels = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)}\n",
        "              for y in train_data.sentiment.values]\n",
        "    split = int(len(train_data) * split)\n",
        "    \n",
        "    train_labels = [{\"cats\": labels} for labels in labels[:split]]\n",
        "    val_labels = [{\"cats\": labels} for labels in labels[split:]]\n",
        "    \n",
        "    return texts[:split], train_labels, texts[split:], val_labels"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBsI5xWQ80or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts, train_labels, val_texts, val_labels = load_data('yelp_ratings.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgu5ZulIPniV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "03ee5365-fa52-4749-807c-d95fd18bc5d5"
      },
      "source": [
        "train_labels[:10]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'cats': {'NEGATIVE': False, 'POSITIVE': True}},\n",
              " {'cats': {'NEGATIVE': False, 'POSITIVE': True}},\n",
              " {'cats': {'NEGATIVE': False, 'POSITIVE': True}},\n",
              " {'cats': {'NEGATIVE': False, 'POSITIVE': True}},\n",
              " {'cats': {'NEGATIVE': True, 'POSITIVE': False}},\n",
              " {'cats': {'NEGATIVE': False, 'POSITIVE': True}},\n",
              " {'cats': {'NEGATIVE': True, 'POSITIVE': False}},\n",
              " {'cats': {'NEGATIVE': True, 'POSITIVE': False}},\n",
              " {'cats': {'NEGATIVE': False, 'POSITIVE': True}},\n",
              " {'cats': {'NEGATIVE': False, 'POSITIVE': True}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERMclN2EPkhl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a1d0a688-7462-4693-9b8a-438d2d230a09"
      },
      "source": [
        "train_texts"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"Some of the best sushi I've ever had....and I come from the East Coast.  Unreal toro, have some of it's available.\",\n",
              "       \"One of the best burgers I've ever had and very well priced. I got the tortilla burger and is was delicious especially with there tortilla soup!\",\n",
              "       'Review by a vegetarian family with two young kids. \\n\\nSeveral reviews have lamented the small number of vegetarian options on the menu and, while it is true that there are far more options for meat eaters and there is unfortunately no vegetarian noodle soup option, once you get over these 2 facts this is an excellent place for vegetarians.',\n",
              "       ...,\n",
              "       'Their chicken wings is the bomb. I live in Mississauga but drove all the way up there for the wings. We ordered honey garlic, sweet chilli and mango chipotle. \\nHalf price wings on Mondays.',\n",
              "       'The pizza is really good! Staff does a great job especially with how busy they seem to get they handle it like champs! Manager is amazing she does a wonderful job and is very good at what she does. Will definitely be back again soon.',\n",
              "       \"This is a great place to eat. The price is right! The margaritas are delicious. It isn't a big place inside. But the food is worth it if you ever have to wait. The staff is friendly as well.\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqi-NrdVPh2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "6b9e178d-deed-4ae0-faf5-40dbf5be85f1"
      },
      "source": [
        "val_texts"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"This magic show was the best one I've ever seen, very funny and great magic!!! We sat in the third row center and couldn't figure out any of the tricks, how does he do it? My sons (8 & 10) absolutely loved the show. My 10 year old volunteered to help on stage, he was super excited and as an extra bonus got a magic kit as a thank you at the end. We will definetely come back to this show, it's perfect family entertainment, loved every second of it!!!\",\n",
              "       \"There are a lot of good food places in Las Vegas, it's just a little bit harder to find them in the North side! It's located inside a gas station, but area seems to look just fine in my opinion! I may say a lot of people are nice in my reviews, but really, the owner is welcoming to his customers and if there are any adjustments that needs to be made he is more than willing to fix it or make up for it somehow. The price here is also great! I have only tried the tacos, but they're all really good with the sauce! You have to get the hot sauce! :)\",\n",
              "       'I did not visit the Kent office, but the office of Dr. Brown in Fairlawn. She was lacking in compassion, clarity, kindness, and professional ethics. She judged me based on my  pharmacutical history, and did not even glance at the stack of medical records I brought with me. I have been treated by some of the best in the country at John Hopkins and Walter Reed, and to be treated so unprofessionally in this office was an insult to the profession. Do NOT waste your time with Dr. Brown!',\n",
              "       ...,\n",
              "       \"I have been fortune to spend around 20 weekends at the Venetian including the first weekend they opened. \\nIt has always been and still is a class hotel. \\nIt has worn well and looks as good it did that first weekend. \\nThe rooms are all suites and some are bigger then others but even in the smallest suite is larger then most hotels junior suite. \\nYou know this hotel got it's act together when there version of a coffee shop is the Grand Lux Cafe , which is a off shoot of The Cheesecake Factory. \\nThey have great restaurants and shows. \\nThe poker room is one of the best. \\nSee you soon old friend.\",\n",
              "       \"The receptionist on the phone is a horrible and rude person. I wish i could give zero stars. She yelled when I asked for information and then yelled she didn't like her job. I think they want to replace her if they want to have a great business.\",\n",
              "       \"Wow! Amazing. My grandmother was a war-bride from Wales in WWII, relocated to the back woods of Alabama in the 40s/50s. She learned how to make the BEST fried chicken, the BEST skillet cornbread, blackeyed peas, collard greens, etc....   \\n\\nThis place reminds me of my beloved grandma's table... God rest her soul. \\n\\nThey just need some sort of beans regularly on the menu.  There were  ALWAYS beans on the table. Lol...\\n\\nFantastic service, excellent food, great cocktails, even crafted old school, off menu cocktails. They nailed it.\\n\\nPeach cobbler, off the hook. Expensive, but worth it.\\n\\nI can't wait to try the Beverly Center location.\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySFnSexP9B-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "bc7c0eee-066c-49e1-c55c-8e0b7fa12ce9"
      },
      "source": [
        "print('Texts from training data\\n------')\n",
        "print(train_texts[:2])\n",
        "print('\\nLabels from training data\\n------')\n",
        "print(train_labels[:2])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texts from training data\n",
            "------\n",
            "[\"Some of the best sushi I've ever had....and I come from the East Coast.  Unreal toro, have some of it's available.\"\n",
            " \"One of the best burgers I've ever had and very well priced. I got the tortilla burger and is was delicious especially with there tortilla soup!\"]\n",
            "\n",
            "Labels from training data\n",
            "------\n",
            "[{'cats': {'POSITIVE': True, 'NEGATIVE': False}}, {'cats': {'POSITIVE': True, 'NEGATIVE': False}}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnc-KVnM9Hsj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a824be3b-c79e-40cd-c77a-c119aedb0eb0"
      },
      "source": [
        "# Create an empty model\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Create the TextCategorizer with exclusive classes and \"bow\" architecture\n",
        "textcat = nlp.create_pipe(\n",
        "              \"textcat\",\n",
        "              config={\n",
        "                \"exclusive_classes\": True,\n",
        "                \"architecture\": \"bow\"})\n",
        "\n",
        "# Add the TextCategorizer to the empty model\n",
        "nlp.add_pipe(textcat)\n",
        "\n",
        "# Add labels to text classifier\n",
        "textcat.add_label(\"NEGATIVE\")\n",
        "textcat.add_label(\"POSITIVE\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwFYJXQOP6AF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef4b8ee0-1b63-4fd2-bf2c-b2130cf5944a"
      },
      "source": [
        "textcat"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.pipes.TextCategorizer at 0x7f6ca37d5c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QHYpXFE-pUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_data, optimizer):\n",
        "    losses = {}\n",
        "    random.seed(1)\n",
        "    random.shuffle(train_data)\n",
        "    \n",
        "    batches = minibatch(train_data, size=8)\n",
        "    for batch in batches:\n",
        "        # train_data is a list of tuples [(text0, label0), (text1, label1), ...]\n",
        "        # Split batch into texts and labels\n",
        "        texts, labels = zip(*batch)\n",
        "        \n",
        "        # Update model with texts and labels\n",
        "        model.update(texts, labels, sgd=optimizer, losses=losses)\n",
        "        \n",
        "    return losses"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjkh5KEd-joz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3784df0e-4d23-438c-a2da-eed2dd550c58"
      },
      "source": [
        "# Fix seed for reproducibility\n",
        "spacy.util.fix_random_seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "# This may take a while to run!\n",
        "optimizer = nlp.begin_training()\n",
        "train_data = list(zip(train_texts, train_labels))\n",
        "losses = train(nlp, train_data, optimizer)\n",
        "print(losses['textcat'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8.704142077092879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjKTs-hz-6G3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c6c276a-402f-42b4-cdc6-e232f8359cfd"
      },
      "source": [
        "text = \"This tea cup was full of holes. Do not recommend.\"\n",
        "doc = nlp(text)\n",
        "print(doc.cats)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'NEGATIVE': 0.7737048864364624, 'POSITIVE': 0.2262951135635376}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpxe34Bk_DAf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Step 4: Making Predictions\n",
        "\n",
        "Implement a function `predict` that predicts the sentiment of text examples. \n",
        "- First, tokenize the texts using `nlp.tokenizer()`. \n",
        "- Then, pass those docs to the TextCategorizer which you can get from `nlp.get_pipe()`. \n",
        "- Use the `textcat.predict()` method to get scores for each document, then choose the class with the highest score (probability) as the predicted class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rhrJeZ9-6we",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(nlp, texts): \n",
        "    # Use the model's tokenizer to tokenize each input text\n",
        "    docs = [nlp.tokenizer(text) for text in texts]\n",
        "    \n",
        "    # Use textcat to get the scores for each doc\n",
        "    textcat = nlp.get_pipe('textcat')\n",
        "    scores, _ = textcat.predict(docs)\n",
        "    \n",
        "    # From the scores, find the class with the highest score/probability\n",
        "    predicted_class = scores.argmax(axis=1)\n",
        "    \n",
        "    return predicted_class"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY-5Txfb_lQ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "1b76ee0a-96b2-41c4-daa8-a6ab369c2d32"
      },
      "source": [
        "texts = val_texts[34:38]\n",
        "predictions = predict(nlp, texts)\n",
        "\n",
        "for p, t in zip(predictions, texts):\n",
        "    print(f\"{textcat.labels[p]}: {t} \\n\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "POSITIVE: Came over and had their \"Pick 2\" lunch combo and chose their best selling 1/2 chicken sandwich with quinoa.  Both were tasty, the chicken salad is a bit creamy but was perfect with quinoa on the side.  This is a good lunch joint, casual and clean! \n",
            "\n",
            "POSITIVE: Went here last night and got oysters, fried okra, fries, and onion rings. I cannot complain. The portions were great and tasty!!! I will definitely be back for more. I cannot wait to try the crawfish boudin and soft shell crab. \n",
            "\n",
            "POSITIVE: This restaurant was fantastic! \n",
            "The concept of eating without vision was intriguing. The dinner was filled with laughs and good conversation. \n",
            "\n",
            "We were lead in a line to our table and each person to their seat. This was not just dark but you could not see something right in front of your face. \n",
            "\n",
            "The waiters/waitresses were all blind and allowed us to see how aware you need to be without the vision. \n",
            "\n",
            "Taking away one sense is said to increase your other senses so as taste and hearing which I believed to be true in this experience. \n",
            "\n",
            "The meal was extremely delicious. I had the chicken and it was cooked to perfection. I also had a surprise beer which was a nice surprise. \n",
            "\n",
            "The whole experience was unlike anything I have ever done and I hope this spreads to other cities. \n",
            "\n",
            "A must do! \n",
            "\n",
            "NEGATIVE: They won't book new patients for same day appointments. My dog is sick but it's not necessarily urgent so I asked when I would be able to book an appointment and was told \"new patients book out at least 6 weeks in advance\" so just a heads up this seems like a great vet from other reviews but it'll be hard to get in their system to know \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgEqFgm6_tTc",
        "colab_type": "text"
      },
      "source": [
        "# Step 5: Evaluate The Model\n",
        "\n",
        "Implement a function that evaluates a `TextCategorizer` model. This function `evaluate` takes a model along with texts and labels. It returns the accuracy of the model, which is the number of correct predictions divided by all predictions.\n",
        "\n",
        "First, use the `predict` method you wrote earlier to get the predicted class for each text in `texts`. Then, find where the predicted labels match the true \"gold-standard\" labels and calculate the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZrhsBq2_nRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, texts, labels):\n",
        "    \"\"\" Returns the accuracy of a TextCategorizer model. \n",
        "    \n",
        "        Arguments\n",
        "        ---------\n",
        "        model: ScaPy model with a TextCategorizer\n",
        "        texts: Text samples, from load_data function\n",
        "        labels: True labels, from load_data function\n",
        "    \n",
        "    \"\"\"\n",
        "    # Get predictions from textcat model\n",
        "    predicted_class = predict(model, texts)\n",
        "\n",
        "    # From labels, get the true class as a list of integers (POSITIVE -> 1, NEGATIVE -> 0)\n",
        "    true_class = [int(each['cats']['POSITIVE']) for each in labels]\n",
        "\n",
        "    # A boolean or int array indicating correct predictions\n",
        "    correct_predictions = predicted_class == true_class\n",
        "\n",
        "    # The accuracy, number of correct predictions divided by all predictions\n",
        "    accuracy = correct_predictions.mean()\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjLxUDCUVf5e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4be17ed3-8631-42af-a5b0-03719ed9e316"
      },
      "source": [
        "accuracy = evaluate(nlp, val_texts, val_labels)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLLsmMj4Vivd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "64bb406a-de98-4aa8-9d0e-7c4aced4b885"
      },
      "source": [
        "# With the functions implemented, can train and evaluate in a loop.\n",
        "n_iters = 5\n",
        "for i in range(n_iters):\n",
        "    losses = train(nlp, train_data, optimizer)\n",
        "    accuracy = evaluate(nlp, val_texts, val_labels)\n",
        "    print(f\"Loss: {losses['textcat']:.3f} \\t Accuracy: {accuracy:.3f}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 4.496 \t Accuracy: 0.945\n",
            "Loss: 3.106 \t Accuracy: 0.946\n",
            "Loss: 2.348 \t Accuracy: 0.945\n",
            "Loss: 1.926 \t Accuracy: 0.944\n",
            "Loss: 1.594 \t Accuracy: 0.945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSmYSHlbV303",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}