{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spaCy_for_NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQfKmncOLf4Z",
        "colab_type": "text"
      },
      "source": [
        "# **spaCy**\n",
        "\n",
        "spaCy is the leading library for NLP, and it has quickly become one of the most popular Python frameworks.\n",
        "\n",
        "We will use [SpaCy](https://spacy.io/) to perform following task:\n",
        "1. Basic text processing and pattern matching\n",
        "2. Building machine learning models with text\n",
        "3. Representing text with word embeddings that numerically capture the meaning of words and documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LMUnzBeK3gt",
        "colab_type": "text"
      },
      "source": [
        "There's a lot you can do with the doc object you just created.\n",
        "\n",
        "**Tokenizing** <br>\n",
        "This returns a document object that contains tokens. A token is a unit of text in the document, such as individual words and punctuation. SpaCy splits contractions like \"don't\" into two tokens, \"do\" and \"n't\". You can see the tokens by iterating through the document.<br>\n",
        "\n",
        "**Text preprocessing** <br>\n",
        "There are a few types of preprocessing to improve how we model with words. The first is \"lemmatizing.\" The \"lemma\" of a word is its base form. For example, \"walk\" is the lemma of the word \"walking\". So, when you lemmatize the word walking, you would convert it to walk.\n",
        "\n",
        "It's also common to remove stopwords. Stopwords are words that occur frequently in the language and don't contain much information. English stopwords include \"the\", \"is\", \"and\", \"but\", \"not\".\n",
        "\n",
        "With a spaCy token, token.lemma_ returns the lemma, while token.is_stop returns a boolean True if the token is a stopword (and False otherwise). <br>\n",
        "\n",
        "**Pattern Matching**<br>\n",
        "Another common NLP task is matching tokens or phrases within chunks of text or whole documents. You can do pattern matching with regular expressions, but spaCy's matching capabilities tend to be easier to use.\n",
        "\n",
        "To match individual tokens, you create a Matcher. When you want to match a list of terms, it's easier and more efficient to use PhraseMatcher. For example, if you want to find where different smartphone models show up in some text, you can create patterns for the model names of interest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS6h2ROfSXnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from collections import defaultdict"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp7khhOmLWvT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "49ba5210-2151-4d84-9504-804c0bacea88"
      },
      "source": [
        "# Load in the data from JSON file\n",
        "data = pd.read_json('restaurant.json')\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>lDJIaF4eYRF4F7g6Zb9euw</td>\n",
              "      <td>lb0QUR5bc4O-Am4hNq9ZGg</td>\n",
              "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>I used to work food service and my manager at ...</td>\n",
              "      <td>2013-01-27 17:54:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>vvIzf3pr8lTqE_AOsxmgaA</td>\n",
              "      <td>MAmijW4ooUzujkufYYLMeQ</td>\n",
              "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>We have been trying Eggplant sandwiches all ov...</td>\n",
              "      <td>2015-04-15 04:50:56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1204</th>\n",
              "      <td>UF-JqzMczZ8vvp_4tPK3bQ</td>\n",
              "      <td>slfi6gf_qEYTXy90Sw93sg</td>\n",
              "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Amazing Steak and Cheese... Better than any Ph...</td>\n",
              "      <td>2011-03-20 00:57:45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1251</th>\n",
              "      <td>geUJGrKhXynxDC2uvERsLw</td>\n",
              "      <td>N_-UepOzAsuDQwOUtfRFGw</td>\n",
              "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Although I have been going to DeFalco's for ye...</td>\n",
              "      <td>2018-07-17 01:48:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1354</th>\n",
              "      <td>aPctXPeZW3kDq36TRm-CqA</td>\n",
              "      <td>139hD7gkZVzSvSzDPwhNNw</td>\n",
              "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Highs: Ambience, value, pizza and deserts. Thi...</td>\n",
              "      <td>2018-01-21 10:52:58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   review_id  ...                date\n",
              "109   lDJIaF4eYRF4F7g6Zb9euw  ... 2013-01-27 17:54:54\n",
              "1013  vvIzf3pr8lTqE_AOsxmgaA  ... 2015-04-15 04:50:56\n",
              "1204  UF-JqzMczZ8vvp_4tPK3bQ  ... 2011-03-20 00:57:45\n",
              "1251  geUJGrKhXynxDC2uvERsLw  ... 2018-07-17 01:48:23\n",
              "1354  aPctXPeZW3kDq36TRm-CqA  ... 2018-01-21 10:52:58\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP0h98zHShkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "menu = [\"Cheese Steak\", \"Cheesesteak\", \"Steak and Cheese\", \"Italian Combo\", \"Tiramisu\", \"Cannoli\",\n",
        "        \"Chicken Salad\", \"Chicken Spinach Salad\", \"Meatball\", \"Pizza\", \"Pizzas\", \"Spaghetti\",\n",
        "        \"Bruchetta\", \"Eggplant\", \"Italian Beef\", \"Purista\", \"Pasta\", \"Calzones\",  \"Calzone\",\n",
        "        \"Italian Sausage\", \"Chicken Cutlet\", \"Chicken Parm\", \"Chicken Parmesan\", \"Gnocchi\",\n",
        "        \"Chicken Pesto\", \"Turkey Sandwich\", \"Turkey Breast\", \"Ziti\", \"Portobello\", \"Reuben\",\n",
        "        \"Mozzarella Caprese\",  \"Corned Beef\", \"Garlic Bread\", \"Pastrami\", \"Roast Beef\",\n",
        "        \"Tuna Salad\", \"Lasagna\", \"Artichoke Salad\", \"Fettuccini Alfredo\", \"Chicken Parmigiana\",\n",
        "        \"Grilled Veggie\", \"Grilled Veggies\", \"Grilled Vegetable\", \"Mac and Cheese\", \"Macaroni\",  \n",
        "         \"Prosciutto\", \"Salami\"]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oU7JqkSStO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_of_review_to_test_on = 14\n",
        "text_to_test_on = data.text.iloc[index_of_review_to_test_on]\n",
        "\n",
        "# Load the SpaCy model\n",
        "nlp = spacy.blank('en')\n",
        "review_doc = nlp(text_to_test_on)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ai_b_h2TnkR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8e372cb-e545-46fb-a593-753cdf9ebf45"
      },
      "source": [
        "nlp"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7f2e560d2160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCKzEc6QTvOa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1c0f8954-1182-4752-b61a-d3c27a627e13"
      },
      "source": [
        "# Example\n",
        "doc = nlp(\"Tea is healthy and calming, don't you think?\")\n",
        "for token in doc:\n",
        "    print(token)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tea\n",
            "is\n",
            "healthy\n",
            "and\n",
            "calming\n",
            ",\n",
            "do\n",
            "n't\n",
            "you\n",
            "think\n",
            "?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr51nSqSUuCy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "a7d3f402-6b35-4b6a-d3ef-4828d2a6beed"
      },
      "source": [
        "# Create the PhraseMatcher object. The tokenizer is the first argument.\n",
        "# Use attr = 'LOWER' to make consistent capitalization\n",
        "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
        "\n",
        "# Create a list of tokens for each item in the menu\n",
        "menu_tokens_list = [nlp(item) for item in menu]\n",
        "menu_tokens_list"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Cheese Steak,\n",
              " Cheesesteak,\n",
              " Steak and Cheese,\n",
              " Italian Combo,\n",
              " Tiramisu,\n",
              " Cannoli,\n",
              " Chicken Salad,\n",
              " Chicken Spinach Salad,\n",
              " Meatball,\n",
              " Pizza,\n",
              " Pizzas,\n",
              " Spaghetti,\n",
              " Bruchetta,\n",
              " Eggplant,\n",
              " Italian Beef,\n",
              " Purista,\n",
              " Pasta,\n",
              " Calzones,\n",
              " Calzone,\n",
              " Italian Sausage,\n",
              " Chicken Cutlet,\n",
              " Chicken Parm,\n",
              " Chicken Parmesan,\n",
              " Gnocchi,\n",
              " Chicken Pesto,\n",
              " Turkey Sandwich,\n",
              " Turkey Breast,\n",
              " Ziti,\n",
              " Portobello,\n",
              " Reuben,\n",
              " Mozzarella Caprese,\n",
              " Corned Beef,\n",
              " Garlic Bread,\n",
              " Pastrami,\n",
              " Roast Beef,\n",
              " Tuna Salad,\n",
              " Lasagna,\n",
              " Artichoke Salad,\n",
              " Fettuccini Alfredo,\n",
              " Chicken Parmigiana,\n",
              " Grilled Veggie,\n",
              " Grilled Veggies,\n",
              " Grilled Vegetable,\n",
              " Mac and Cheese,\n",
              " Macaroni,\n",
              " Prosciutto,\n",
              " Salami]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_64qilcoYLW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
        "menu_tokens_list = [nlp(item) for item in menu]\n",
        "matcher.add(\"MENU\", None, *menu_tokens_list)\n",
        "matches = matcher(review_doc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}