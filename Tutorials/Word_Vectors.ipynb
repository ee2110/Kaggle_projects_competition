{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_Vectors.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTgIJcOscWvL",
        "colab_type": "text"
      },
      "source": [
        "# **Word embeddings**\n",
        "\n",
        "Word embeddings (also called word vectors) represent each word numerically in such a way that the vector corresponds to how that word is used or what it means. Vector encodings are learned by considering the context in which the words appear. Words that appear in similar contexts will have similar vectors. For example, vectors for \"leopard\", \"lion\", and \"tiger\" will be close together, while they'll be far away from \"planet\" and \"castle\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYtC2jYecV9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbZfDKNQlqjw",
        "colab_type": "text"
      },
      "source": [
        "spaCy provides embeddings learned from a model called Word2Vec. You can access them by loading a large language model like `en_core_web_lg`. Then they will be available on tokens from the `.vector` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdAhhgG0Xgmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "321bf2cb-9ac3-4a32-8d88-86a8228dece5"
      },
      "source": [
        "# Load the large model to get the vectors\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "review_data = pd.read_csv('yelp_ratings.csv')\n",
        "review_data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>stars</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Total bill for this horrible service? Over $8G...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I have to say that this office really has it t...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Today was my second out of three sessions I ha...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  stars  sentiment\n",
              "0  Total bill for this horrible service? Over $8G...    1.0          0\n",
              "1  I *adore* Travis at the Hard Rock's new Kelly ...    5.0          1\n",
              "2  I have to say that this office really has it t...    5.0          1\n",
              "3  Went in for a lunch. Steak sandwich was delici...    5.0          1\n",
              "4  Today was my second out of three sessions I ha...    1.0          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUC6lSSQncuf",
        "colab_type": "text"
      },
      "source": [
        "Here's an example of loading some document vectors.\n",
        "\n",
        "Calculating 44,500 document vectors takes about 20 minutes, so we'll get only the first 100. To save time, we'll load pre-saved document vectors for the hands-on coding exercises."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqn68QW_mqPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "792103df-998f-4520-9ee5-3491f3638627"
      },
      "source": [
        "reviews = review_data[:100]\n",
        "# We just want the vectors so we can turn off other models in the pipeline\n",
        "with nlp.disable_pipes():\n",
        "    vectors = np.array([nlp(review.text).vector for idx, review in reviews.iterrows()])\n",
        "    \n",
        "vectors.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 96)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7aRg8kTqGtX",
        "colab_type": "text"
      },
      "source": [
        "Why 100 rows? Because we have 1 row for each column.\n",
        "\n",
        "Why 300 columns? This is the same length as word vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEiZgdMEnjtf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "6d5b32ec-cef9-4600-f70a-a813e890e498"
      },
      "source": [
        "# Loading all document vectors from file\n",
        "vectors = np.load('review_vectors.npy')\n",
        "vectors"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.20143504,  0.1837154 , -0.01327053, ..., -0.05922916,\n",
              "         0.01440009,  0.09077955],\n",
              "       [-0.02590548,  0.1517007 , -0.11389936, ..., -0.04916738,\n",
              "         0.03085417,  0.07205424],\n",
              "       [-0.07666641,  0.19274631, -0.14321738, ..., -0.04575825,\n",
              "         0.0689992 ,  0.09280958],\n",
              "       ...,\n",
              "       [-0.03841371,  0.16862842, -0.24175283, ..., -0.10739233,\n",
              "         0.14741549,  0.12238124],\n",
              "       [-0.01221176,  0.11620302, -0.09448893, ..., -0.06332556,\n",
              "         0.02805696,  0.13142744],\n",
              "       [ 0.01070178,  0.1630349 , -0.06763948, ..., -0.08762769,\n",
              "         0.00377347,  0.15404755]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK9bIYcKxW2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0ad9abb-faf5-41a5-916e-6f1101cdc862"
      },
      "source": [
        "vectors.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44530, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7AUnuxuxgIz",
        "colab_type": "text"
      },
      "source": [
        "# **Training a Model on Document Vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOo2pqqfxbYU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c1908ae-dd87-4e7b-d2c9-2d56a9eb5c74"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(vectors, review_data.sentiment, \n",
        "                                                    test_size=0.1, random_state=1)\n",
        "\n",
        "# Create the LinearSVC model\n",
        "model = LinearSVC(random_state=1, dual=False)\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# to see model accuracy\n",
        "print(f'Model test accuracy: {model.score(X_test, y_test)*100:.3f}%')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model test accuracy: 93.847%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw9pYs7SxZIt",
        "colab_type": "text"
      },
      "source": [
        "**Centering the Vectors**\n",
        "\n",
        "Sometimes people center document vectors when calculating similarities. That is, they calculate the mean vector from all documents, and they subtract this from each individual document's vector. Why do you think this could help with similarity metrics?\n",
        "\n",
        "Sometimes your documents will already be fairly similar. For example, this data set is all reviews of businesses. There will be stong similarities between the documents compared to news articles, technical manuals, and recipes. You end up with all the similarities between 0.8 and 1 and no anti-similar documents (similarity < 0). When the vectors are centered, you are comparing documents within your dataset as opposed to all possible documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKYyCjKzx21C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "8e99e342-10b6-4cb9-ce1c-97c4845ecfe5"
      },
      "source": [
        "review = \"\"\"I absolutely love this place. The 360 degree glass windows with the \n",
        "Yerba buena garden view, tea pots all around and the smell of fresh tea everywhere \n",
        "transports you to what feels like a different zen zone within the city. I know \n",
        "the price is slightly more compared to the normal American size, however the food \n",
        "is very wholesome, the tea selection is incredible and I know service can be hit \n",
        "or miss often but it was on point during our most recent visit. Definitely recommend!\n",
        "\n",
        "I would especially recommend the butternut squash gyoza.\"\"\"\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b)/np.sqrt(a.dot(a)*b.dot(b))\n",
        "\n",
        "review_vec = nlp(review).vector\n",
        "\n",
        "## Center the document vectors\n",
        "# Calculate the mean for the document vectors\n",
        "vec_mean = vectors.mean(axis=0)\n",
        "# Subtract the mean from the vectors\n",
        "centered = vectors - vec_mean\n",
        "\n",
        "# Calculate similarities for each document in the dataset\n",
        "# Make sure to subtract the mean from the review vector\n",
        "sims = np.array([cosine_similarity(review_vec - vec_mean, vec) for vec in centered])\n",
        "\n",
        "# Get the index for the most similar document\n",
        "most_similar = sims.argmax()\n",
        "\n",
        "print(review_data.iloc[most_similar].text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-6ba35aac2fda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Calculate similarities for each document in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Make sure to subtract the mean from the review vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_vec\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvec_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcentered\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Get the index for the most similar document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-6ba35aac2fda>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Calculate similarities for each document in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Make sure to subtract the mean from the review vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_vec\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvec_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcentered\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Get the index for the most similar document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (96,) (300,) "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FqdwUdt1cF5",
        "colab_type": "text"
      },
      "source": [
        "**Looking at similar reviews**\n",
        "\n",
        "Reviews for coffee shops will also be similar to our tea house review because coffee and tea are semantically similar. Most cafes serve both coffee and tea so you'll see the terms appearing together often."
      ]
    }
  ]
}